import torch
import torch.nn as nn
from rfdetr import RFDETRNano
import onnx
from onnx import shape_inference
import argparse


# --- 1. JIT Script (å…³é”®ä¿®æ”¹ï¼šæ˜¾å¼ reshape) ---
@torch.jit.script
def post_process_script(pred_boxes, pred_logits, max_detections: int, num_classes: int):
    # pred_boxes: [Batch, 300, 4]
    # pred_logits: [Batch, 300, 91]

    batch_size = pred_logits.size(0)

    # Sigmoid
    probs = pred_logits.sigmoid()

    # TopK
    topk_values, topk_indices = torch.topk(probs.max(-1)[0], k=max_detections, dim=1)

    # æ„é€  Gather ç´¢å¼•
    # [Batch, K] -> [Batch, K, 1] -> [Batch, K, 4]
    indices_boxes = topk_indices.unsqueeze(-1).expand(batch_size, max_detections, 4)

    # [Batch, K] -> [Batch, K, C]
    indices_logits = topk_indices.unsqueeze(-1).expand(batch_size, max_detections, num_classes)

    # Gather
    new_boxes = torch.gather(pred_boxes, 1, indices_boxes)
    new_probs = torch.gather(probs, 1, indices_logits)

    # --- å…³é”®ä¿®æ”¹ç‚¹ ---
    # å¼ºåˆ¶ Reshape:
    # -1 è¡¨ç¤º Batch ç»´åº¦ç»§ç»­ä¿æŒåŠ¨æ€
    # max_detections, 4, num_classes æ˜¯æˆ‘ä»¬ä¼ å…¥çš„æ•´æ•°ï¼ŒONNX ä¼šæŠŠå®ƒä»¬è¯†åˆ«ä¸ºå›ºå®šå¸¸æ•°
    new_boxes = new_boxes.view(-1, max_detections, 4)
    new_probs = new_probs.view(-1, max_detections, num_classes)

    return new_boxes, new_probs


# --- 2. åŒ…è£…å™¨ ---
class DeployModel(nn.Module):
    def __init__(self, core_model, max_detections=100, num_classes=91):
        super().__init__()
        self.core_model = core_model
        self.max_detections = max_detections
        self.num_classes = num_classes  # è®°å½•ç±»åˆ«æ•°

        # æ³¨å†Œé¢„å¤„ç†å¸¸é‡
        self.register_buffer('mean', torch.tensor([123.675, 116.28, 103.53]).view(1, 3, 1, 1))
        self.register_buffer('std', torch.tensor([58.395, 57.12, 57.375]).view(1, 3, 1, 1))

    def forward(self, x):
        # é¢„å¤„ç†
        x = x.float()
        x = x[:, [2, 1, 0], :, :]
        x = (x - self.mean) / self.std

        outputs = self.core_model(x)

        if isinstance(outputs, dict):
            pred_boxes = outputs['pred_boxes']
            pred_logits = outputs['pred_logits']
        elif isinstance(outputs, (list, tuple)):
            pred_boxes = outputs[0]
            pred_logits = outputs[1]
        else:
            pred_boxes, pred_logits = outputs

        # è¿™é‡Œçš„ 91 (æˆ– 80) é€šå¸¸æ˜¯å›ºå®šçš„ï¼Œæˆ‘ä»¬ç›´æ¥ä¼ è¿›å»
        # æ³¨æ„ï¼šRF-DETR COCO é»˜è®¤æ˜¯ 91 (å«èƒŒæ™¯ä½) æˆ– 80ï¼Œå–å†³äºå…·ä½“æƒé‡
        # æˆ‘ä»¬è¿™é‡Œé€šè¿‡ pred_logits.shape[-1] è·å–çœŸå®å€¼ä¼ ç»™ JIT
        real_num_classes = pred_logits.shape[-1]

        return post_process_script(pred_boxes, pred_logits, self.max_detections, real_num_classes)


def main(modelpath, onnxbest, resolution, max_detections=100):
    # 1. åˆå§‹åŒ–
    rfdetr_wrapper = RFDETRNano(
        pretrain_weights=modelpath,
        resolution=resolution,
        device='cpu',
        num_queries=max_detections,
        num_select=max_detections
    )

    if hasattr(rfdetr_wrapper.model, 'model') and isinstance(rfdetr_wrapper.model.model, nn.Module):
        core_model = rfdetr_wrapper.model.model
    elif isinstance(rfdetr_wrapper.model, nn.Module):
        core_model = rfdetr_wrapper.model
    else:
        raise RuntimeError("âŒ æ— æ³•æ‰¾åˆ°åº•å±‚çš„ PyTorch nn.Module")

    core_model.eval()

    # 2. åŒ…è£…
    deploy_model = DeployModel(core_model, max_detections=max_detections)
    deploy_model.eval()

    # 3. å¯¼å‡º
    dummy_input = torch.zeros(1, 3, resolution, resolution, dtype=torch.uint8)

    dynamic_axes_config = {
        'input': {0: 'batch'},
        'boxes': {0: 'batch'},
        'scores': {0: 'batch'}
    }

    print(f"æ­£åœ¨å¯¼å‡º ONNX (Res={resolution}, TopK={max_detections})...")

    # å¯¼å‡º
    torch.onnx.export(
        deploy_model,
        dummy_input,
        onnxbest,
        input_names=['input'],
        output_names=['boxes', 'scores'],
        opset_version=16,
        do_constant_folding=True,
        dynamic_axes=dynamic_axes_config
    )

    print(f"âœ… å¯¼å‡ºå®Œæˆï¼Œæ­£åœ¨è¿›è¡Œå½¢çŠ¶æ¨æ–­(Shape Inference)...")

    # 4. å…³é”®åå¤„ç†ï¼šå½¢çŠ¶æ¨æ–­
    # è¿™ä¸€æ­¥ä¼šè®¡ç®—å‡ºæ‰€æœ‰èƒ½ç¡®å®šçš„å½¢çŠ¶ï¼ŒæŠŠé‚£äº› GatherElements... å˜æˆçœŸæ­£çš„æ•°å­—
    try:
        model = onnx.load(onnxbest)
        # æ¨æ–­å½¢çŠ¶
        model = shape_inference.infer_shapes(model)
        onnx.save(model, onnxbest)

        print(f"ğŸ‰ å®Œç¾å¤„ç†å®Œæˆ: {onnxbest}")
        print("   - è¾“å…¥: [batch, 3, H, W]")
        # æ‰“å°æœ€ç»ˆå½¢çŠ¶éªŒè¯
        out0_shape = [d.dim_param if d.dim_param else d.dim_value for d in
                      model.graph.output[0].type.tensor_type.shape.dim]
        out1_shape = [d.dim_param if d.dim_param else d.dim_value for d in
                      model.graph.output[1].type.tensor_type.shape.dim]

        print(f"   - boxes:  {out0_shape}  (æœŸæœ›: ['batch', {max_detections}, 4])")
        print(f"   - scores: {out1_shape} (æœŸæœ›: ['batch', {max_detections}, 91])")

    except Exception as e:
        print(f"âš ï¸ å½¢çŠ¶æ¨æ–­è­¦å‘Š: {e}")


if __name__ == '__main__':
    parse = argparse.ArgumentParser()
    parse.add_argument('--weight-path', dest='weight_pth', type=str, default='pt/v1/checkpoint_best_regular.pth')
    parse.add_argument('--outpath', dest='out_pth', type=str, default='./onnx/best-smi.onnx')
    parse.add_argument('--resolution', type=int, default=384)
    parse.add_argument('--max-detections', type=int, default=150)
    args = parse.parse_args()

    main(args.weight_pth, args.out_pth, args.resolution, args.max_detections)